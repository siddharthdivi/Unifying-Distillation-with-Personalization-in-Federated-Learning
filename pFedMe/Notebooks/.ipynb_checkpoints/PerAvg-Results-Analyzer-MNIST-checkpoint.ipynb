{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to help read the h5 files.\n",
    "def simple_read_data(fileName):\n",
    "    print(fileName)\n",
    "    hf = h5py.File('{}.h5'.format(fileName), 'r')\n",
    "    \n",
    "    # We'll return a dictionary object. \n",
    "    results = {}\n",
    "    \n",
    "    results['rs_glob_acc'] = np.array(hf.get('rs_glob_acc')[:])\n",
    "    results['rs_train_acc'] = np.array(hf.get('rs_train_acc')[:])\n",
    "    results['rs_train_loss'] = np.array(hf.get('rs_train_loss')[:])\n",
    "    \n",
    "    # 3D array: Read as [number of times, number of epochs, number of users].\n",
    "    results['perUserAccs'] = np.array(hf.get('perUserAccs'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-1 Latest attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.99]\n",
      "\n",
      " Average accuracy across all the different runs : 0.990000.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9917]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [0.9917]\n",
      " [0.9917]\n",
      " [0.9833]\n",
      " [0.9833]\n",
      " [0.975 ]\n",
      " [0.9833]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.990000.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.0025_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9425]\n",
      "\n",
      " Average accuracy across all the different runs : 0.942500.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [0.9833]\n",
      " [1.    ]\n",
      " [0.525 ]\n",
      " [0.9667]\n",
      " [0.9667]\n",
      " [0.9833]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.942500.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.0025_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.005_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8608333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.860833.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [1.    ]\n",
      " [0.875 ]\n",
      " [0.9667]\n",
      " [0.5083]\n",
      " [1.    ]\n",
      " [0.7833]\n",
      " [0.475 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.860830.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.005_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.0075_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.7533333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.753333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9917]\n",
      " [0.9917]\n",
      " [0.525 ]\n",
      " [0.975 ]\n",
      " [0.8667]\n",
      " [0.95  ]\n",
      " [0.5083]\n",
      " [0.675 ]\n",
      " [0.525 ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.753340.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.0075_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.01_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8658333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.865833.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9917]\n",
      " [0.975 ]\n",
      " [0.9417]\n",
      " [0.9667]\n",
      " [0.95  ]\n",
      " [0.8833]\n",
      " [0.8083]\n",
      " [0.4667]\n",
      " [0.9833]\n",
      " [0.6917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.865840.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.01_15_10u_128b_20_0_roundNum_0_globalIters_1000_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8823931040368695]\n",
      "\n",
      " Average accuracy across all the different runs : 0.882393.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9083]\n",
      " [0.8579]\n",
      " [0.8547]\n",
      " [0.8859]\n",
      " [0.884 ]\n",
      " [0.9128]\n",
      " [0.8798]\n",
      " [0.8848]\n",
      " [0.8583]\n",
      " [0.8912]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.881770.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8806008363915678]\n",
      "\n",
      " Average accuracy across all the different runs : 0.880601.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9083]\n",
      " [0.8566]\n",
      " [0.8529]\n",
      " [0.8845]\n",
      " [0.8792]\n",
      " [0.9091]\n",
      " [0.8816]\n",
      " [0.8907]\n",
      " [0.8571]\n",
      " [0.882 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.880200.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8784671844328753]\n",
      "\n",
      " Average accuracy across all the different runs : 0.878467.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9013]\n",
      " [0.8662]\n",
      " [0.8555]\n",
      " [0.8749]\n",
      " [0.8749]\n",
      " [0.91  ]\n",
      " [0.8835]\n",
      " [0.8863]\n",
      " [0.8532]\n",
      " [0.8843]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.879010.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8727489971835795]\n",
      "\n",
      " Average accuracy across all the different runs : 0.872749.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.8904]\n",
      " [0.8552]\n",
      " [0.8477]\n",
      " [0.8646]\n",
      " [0.8749]\n",
      " [0.9063]\n",
      " [0.8751]\n",
      " [0.8878]\n",
      " [0.8481]\n",
      " [0.8855]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.873560.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.972674473959821]\n",
      "\n",
      " Average accuracy across all the different runs : 0.972674.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9759]\n",
      " [0.961 ]\n",
      " [0.9603]\n",
      " [0.9672]\n",
      " [0.9735]\n",
      " [0.9801]\n",
      " [0.9664]\n",
      " [0.9799]\n",
      " [0.9719]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.972230.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.971055888793678]\n",
      "\n",
      " Average accuracy across all the different runs : 0.971056.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9872]\n",
      " [0.9737]\n",
      " [0.9587]\n",
      " [0.9582]\n",
      " [0.9684]\n",
      " [0.9719]\n",
      " [0.9793]\n",
      " [0.9636]\n",
      " [0.9782]\n",
      " [0.9678]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.970700.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0075_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9684851947062744]\n",
      "\n",
      " Average accuracy across all the different runs : 0.968485.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.984 ]\n",
      " [0.9716]\n",
      " [0.9552]\n",
      " [0.9528]\n",
      " [0.9636]\n",
      " [0.9712]\n",
      " [0.9793]\n",
      " [0.9627]\n",
      " [0.974 ]\n",
      " [0.9654]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.967980.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.005_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9664857659716272]\n",
      "\n",
      " Average accuracy across all the different runs : 0.966486.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.984 ]\n",
      " [0.9683]\n",
      " [0.9518]\n",
      " [0.9475]\n",
      " [0.96  ]\n",
      " [0.9735]\n",
      " [0.9768]\n",
      " [0.9591]\n",
      " [0.9707]\n",
      " [0.9662]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.965790.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.0025_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9966666666666667, 0.9891666666666666, 0.9891666666666666, 0.9866666666666667, 0.9941666666666666]\n",
      "\n",
      " Average accuracy across all the different runs : 0.991167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.99  ]\n",
      " [0.9983]\n",
      " [0.9833]\n",
      " [0.985 ]\n",
      " [0.99  ]\n",
      " [0.99  ]\n",
      " [0.9967]\n",
      " [0.9983]\n",
      " [0.99  ]\n",
      " [0.99  ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.991160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9891666666666666, 0.9908333333333333, 0.9925, 0.9908333333333333, 0.9958333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.991833.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9883]\n",
      " [0.9983]\n",
      " [0.9967]\n",
      " [0.985 ]\n",
      " [0.9917]\n",
      " [0.9917]\n",
      " [0.995 ]\n",
      " [0.9933]\n",
      " [0.9883]\n",
      " [0.99  ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.991830.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9875, 0.9908333333333333, 0.9891666666666666, 0.9941666666666666, 0.9958333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.991500.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.99  ]\n",
      " [0.9883]\n",
      " [0.9983]\n",
      " [0.9867]\n",
      " [0.995 ]\n",
      " [0.9883]\n",
      " [0.995 ]\n",
      " [1.    ]\n",
      " [0.9867]\n",
      " [0.9867]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.991500.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_150_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_150_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_150_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_150_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_150_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9958333333333333, 0.9933333333333333, 0.9975, 0.9933333333333333, 0.9958333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.995167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9917]\n",
      " [0.9967]\n",
      " [0.9983]\n",
      " [0.99  ]\n",
      " [0.9933]\n",
      " [0.9967]\n",
      " [0.995 ]\n",
      " [0.9983]\n",
      " [0.9933]\n",
      " [0.9983]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.995160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_150_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_150_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_150_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_150_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_150_dataSplit_1',\n",
    "]\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9975, 0.9916666666666667, 0.995, 0.9941666666666666, 0.9966666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.995000.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.995 ]\n",
      " [0.9967]\n",
      " [0.9983]\n",
      " [0.99  ]\n",
      " [0.9933]\n",
      " [0.995 ]\n",
      " [0.9967]\n",
      " [0.9983]\n",
      " [0.99  ]\n",
      " [0.9967]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.995000.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_200_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_200_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_200_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_200_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_200_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_300_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_300_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_300_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_300_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_300_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9941666666666666, 0.99, 0.9958333333333333, 0.9941666666666666, 0.9975]\n",
      "\n",
      " Average accuracy across all the different runs : 0.994333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.995 ]\n",
      " [0.995 ]\n",
      " [1.    ]\n",
      " [0.9867]\n",
      " [0.9933]\n",
      " [0.995 ]\n",
      " [0.9933]\n",
      " [1.    ]\n",
      " [0.9933]\n",
      " [0.9917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.994330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_300_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_300_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_300_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_300_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_300_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.1899112325025606, 0.2224972262524537, 0.1870626386755419, 0.18443287530937955, 0.21991807475678443]\n",
      "\n",
      " Average accuracy across all the different runs : 0.200764.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.2245]\n",
      " [0.1798]\n",
      " [0.2219]\n",
      " [0.1778]\n",
      " [0.191 ]\n",
      " [0.2351]\n",
      " [0.1794]\n",
      " [0.2023]\n",
      " [0.1883]\n",
      " [0.1785]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.197860.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_2',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.21526118129054284, 0.25083212426389007, 0.2019969278033794, 0.2388836732952121, 0.2667690732206861]\n",
      "\n",
      " Average accuracy across all the different runs : 0.234749.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.2869]\n",
      " [0.2441]\n",
      " [0.2264]\n",
      " [0.2494]\n",
      " [0.2228]\n",
      " [0.2581]\n",
      " [0.2003]\n",
      " [0.221 ]\n",
      " [0.2204]\n",
      " [0.1906]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.232000.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_2',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.22388187094571527, 0.26773064777673466, 0.23724185014507596, 0.25211231543910556, 0.2767537122375832]\n",
      "\n",
      " Average accuracy across all the different runs : 0.251544.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3032]\n",
      " [0.2701]\n",
      " [0.2328]\n",
      " [0.2753]\n",
      " [0.2292]\n",
      " [0.2921]\n",
      " [0.2139]\n",
      " [0.2355]\n",
      " [0.2282]\n",
      " [0.2119]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.249220.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_200_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.22243086377603277, 0.27293675855594435, 0.24159412869090288, 0.26781599385508237, 0.27863116572793994]\n",
      "\n",
      " Average accuracy across all the different runs : 0.256682.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3126]\n",
      " [0.2569]\n",
      " [0.2554]\n",
      " [0.2674]\n",
      " [0.2489]\n",
      " [0.2964]\n",
      " [0.2366]\n",
      " [0.2254]\n",
      " [0.2272]\n",
      " [0.2029]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.252970.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_200_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_200_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_200_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_200_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_200_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasplit-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.4003809523809524, 0.4108180173316827, 0.3916769831444624, 0.4003809523809524, 0.39895238095238095]\n",
      "\n",
      " Average accuracy across all the different runs : 0.400442.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4018]\n",
      " [0.3482]\n",
      " [0.3685]\n",
      " [0.5184]\n",
      " [0.3786]\n",
      " [0.3954]\n",
      " [0.477 ]\n",
      " [0.3842]\n",
      " [0.4039]\n",
      " [0.3674]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.404340.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_25_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_25_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_25_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_25_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_25_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.3919047619047619, 0.37196457480239975, 0.3758689648604895, 0.3920952380952381, 0.38123809523809526]\n",
      "\n",
      " Average accuracy across all the different runs : 0.382614.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3824]\n",
      " [0.365 ]\n",
      " [0.3836]\n",
      " [0.4777]\n",
      " [0.3732]\n",
      " [0.3763]\n",
      " [0.4672]\n",
      " [0.358 ]\n",
      " [0.3219]\n",
      " [0.3695]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.387480.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_50_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_50_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_50_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_50_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_50_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.39876190476190476, 0.406913627273593, 0.3721550328540139, 0.3994285714285714, 0.382]\n",
      "\n",
      " Average accuracy across all the different runs : 0.391852.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3985]\n",
      " [0.3386]\n",
      " [0.3838]\n",
      " [0.5042]\n",
      " [0.3757]\n",
      " [0.3847]\n",
      " [0.4454]\n",
      " [0.3813]\n",
      " [0.3769]\n",
      " [0.3662]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.395530.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_0_globalIters_100_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_1_globalIters_100_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_2_globalIters_100_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_3_globalIters_100_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.001_15_10u_128b_20_avg_roundNum_4_globalIters_100_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_1_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_2_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_3_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_4_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.99, 0.99, 0.9966666666666667, 0.9766666666666667, 0.9916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.989000.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9733]\n",
      " [0.99  ]\n",
      " [0.9967]\n",
      " [0.9867]\n",
      " [0.99  ]\n",
      " [0.9883]\n",
      " [0.9917]\n",
      " [0.9933]\n",
      " [0.9883]\n",
      " [0.9917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.989000.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_0_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_1_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_2_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_3_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.001_0.001_15_10u_128b_20_0_roundNum_4_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_1_globalIters_800_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_2_globalIters_800_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_3_globalIters_800_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_4_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8823931040368695, 0.8708080894274256, 0.8724076128701886, 0.875405359276327, 0.8741252773510838]\n",
      "\n",
      " Average accuracy across all the different runs : 0.875028.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.875 ]\n",
      " [0.8613]\n",
      " [0.8622]\n",
      " [0.8746]\n",
      " [0.8804]\n",
      " [0.8681]\n",
      " [0.8789]\n",
      " [0.8821]\n",
      " [0.8851]\n",
      " [0.8907]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.875840.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_1_globalIters_800_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_2_globalIters_800_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_3_globalIters_800_dataSplit_2',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_4_globalIters_800_dataSplit_2',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/tempResults/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/tempResults/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/tempResults/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_1_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/tempResults/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_2_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/tempResults/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_3_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/tempResults/Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_4_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.972674473959821, 0.9715319432543083, 0.9754332508093696, 0.969053513616454, 0.9756236907255761]\n",
      "\n",
      " Average accuracy across all the different runs : 0.972863.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9859]\n",
      " [0.9764]\n",
      " [0.9677]\n",
      " [0.9595]\n",
      " [0.9712]\n",
      " [0.9773]\n",
      " [0.9816]\n",
      " [0.969 ]\n",
      " [0.9648]\n",
      " [0.9735]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.972690.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_0_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_1_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_2_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_3_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.01_0.01_15_10u_128b_20_avg_roundNum_4_globalIters_800_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST pFedMe paper check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_1_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_2_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_3_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_4_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9724840521755689, 0.9691516709511568, 0.9726718720243763, 0.966006474957151, 0.9738145115216149]\n",
      "\n",
      " Average accuracy across all the different runs : 0.970826.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9851]\n",
      " [0.9742]\n",
      " [0.9642]\n",
      " [0.9531]\n",
      " [0.9697]\n",
      " [0.9768]\n",
      " [0.982 ]\n",
      " [0.9656]\n",
      " [0.9625]\n",
      " [0.9723]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.970550.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_0_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_1_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_2_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_3_globalIters_800_dataSplit_3',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_4_globalIters_800_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_1_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_2_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_3_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_4_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332, 0.14083333333333334, 0.2125, 0.18916666666666668, 0.18833333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.182833.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.0817]\n",
      " [0.1067]\n",
      " [0.    ]\n",
      " [0.3033]\n",
      " [0.1033]\n",
      " [0.0883]\n",
      " [0.275 ]\n",
      " [0.3667]\n",
      " [0.29  ]\n",
      " [0.2133]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.182830.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_1_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_2_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_3_globalIters_800_dataSplit_1',\n",
    "    'Mnist_PerAvg_p_0.02_0.001_15_10u_20b_20_avg_roundNum_4_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1,:]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
