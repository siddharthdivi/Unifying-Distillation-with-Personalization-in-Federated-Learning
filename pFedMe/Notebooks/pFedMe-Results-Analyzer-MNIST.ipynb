{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to help read the h5 files.\n",
    "def simple_read_data(fileName):\n",
    "    print(fileName)\n",
    "    hf = h5py.File('{}.h5'.format(fileName), 'r')\n",
    "    \n",
    "    # We'll return a dictionary object. \n",
    "    results = {}\n",
    "    \n",
    "    results['rs_glob_acc'] = np.array(hf.get('rs_glob_acc')[:])\n",
    "    results['rs_train_acc'] = np.array(hf.get('rs_train_acc')[:])\n",
    "    results['rs_train_loss'] = np.array(hf.get('rs_train_loss')[:])\n",
    "    \n",
    "    # 3D array: Read as [number of times, number of epochs, number of users].\n",
    "    results['perUserAccs'] = np.array(hf.get('perUserAccs'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/Datasplit-1_MNIST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-1 try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.33916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.339167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.525 ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5083]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.339160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9533333333333334]\n",
      "\n",
      " Average accuracy across all the different runs : 0.953333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.95  ]\n",
      " [1.    ]\n",
      " [0.9583]\n",
      " [0.9583]\n",
      " [0.9083]\n",
      " [0.9   ]\n",
      " [0.95  ]\n",
      " [0.95  ]\n",
      " [0.975 ]\n",
      " [0.9833]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.953320.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.0025_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9416666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.941667.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9417]\n",
      " [0.9583]\n",
      " [0.9417]\n",
      " [0.9583]\n",
      " [0.925 ]\n",
      " [0.9167]\n",
      " [0.9333]\n",
      " [0.925 ]\n",
      " [0.9417]\n",
      " [0.975 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.941670.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.0025_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8841666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.884167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.925 ]\n",
      " [0.925 ]\n",
      " [0.9   ]\n",
      " [0.9083]\n",
      " [0.8833]\n",
      " [0.7333]\n",
      " [0.9   ]\n",
      " [0.8833]\n",
      " [0.8917]\n",
      " [0.8917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.884160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8333333333333334]\n",
      "\n",
      " Average accuracy across all the different runs : 0.833333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9417]\n",
      " [0.9333]\n",
      " [0.8917]\n",
      " [0.5333]\n",
      " [0.8833]\n",
      " [0.8917]\n",
      " [0.4417]\n",
      " [0.9583]\n",
      " [0.95  ]\n",
      " [0.9083]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.833330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.765]\n",
      "\n",
      " Average accuracy across all the different runs : 0.765000.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9083]\n",
      " [0.9167]\n",
      " [0.45  ]\n",
      " [0.9167]\n",
      " [0.9   ]\n",
      " [0.8917]\n",
      " [0.325 ]\n",
      " [0.95  ]\n",
      " [0.9417]\n",
      " [0.45  ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.765010.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.5033333333333333]\n",
      "\n",
      " Average accuracy across all the different runs : 0.503333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.475 ]\n",
      " [0.4667]\n",
      " [0.9417]\n",
      " [0.3917]\n",
      " [0.4583]\n",
      " [0.0083]\n",
      " [0.9167]\n",
      " [0.95  ]\n",
      " [0.0167]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.503340.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1200_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.33916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.339167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.525 ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5083]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.339160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.33916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.339167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.525 ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5083]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.339160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.18333333333333332]\n",
      "\n",
      " Average accuracy across all the different runs : 0.183333.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.    ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.183330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.33916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.339167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.525 ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5083]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.339160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.33916666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.339167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4083]\n",
      " [0.525 ]\n",
      " [0.    ]\n",
      " [0.5167]\n",
      " [0.    ]\n",
      " [0.    ]\n",
      " [0.5083]\n",
      " [0.4583]\n",
      " [0.45  ]\n",
      " [0.525 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.339160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9125]\n",
      "\n",
      " Average accuracy across all the different runs : 0.912500.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.95  ]\n",
      " [0.925 ]\n",
      " [0.9   ]\n",
      " [0.9167]\n",
      " [0.9167]\n",
      " [0.8167]\n",
      " [0.95  ]\n",
      " [0.9167]\n",
      " [0.9167]\n",
      " [0.9167]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.912520.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1000_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9116666666666666]\n",
      "\n",
      " Average accuracy across all the different runs : 0.911667.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.95  ]\n",
      " [0.925 ]\n",
      " [0.9083]\n",
      " [0.9083]\n",
      " [0.9167]\n",
      " [0.8083]\n",
      " [0.95  ]\n",
      " [0.9167]\n",
      " [0.9167]\n",
      " [0.9167]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.911670.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1000_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9141666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.914167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.95  ]\n",
      " [0.925 ]\n",
      " [0.9083]\n",
      " [0.9167]\n",
      " [0.9167]\n",
      " [0.8083]\n",
      " [0.95  ]\n",
      " [0.9167]\n",
      " [0.9333]\n",
      " [0.9167]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.914170.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1200_dataSplit_1',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9697229363039132]\n",
      "\n",
      " Average accuracy across all the different runs : 0.969723.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.965 ]\n",
      " [0.9495]\n",
      " [0.9561]\n",
      " [0.9709]\n",
      " [0.9727]\n",
      " [0.9768]\n",
      " [0.9673]\n",
      " [0.9749]\n",
      " [0.9719]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.969120.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9716271541464343]\n",
      "\n",
      " Average accuracy across all the different runs : 0.971627.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9694]\n",
      " [0.9564]\n",
      " [0.9603]\n",
      " [0.9721]\n",
      " [0.9751]\n",
      " [0.9784]\n",
      " [0.9664]\n",
      " [0.9765]\n",
      " [0.9711]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.971180.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9736265828810816]\n",
      "\n",
      " Average accuracy across all the different runs : 0.973627.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9872]\n",
      " [0.9726]\n",
      " [0.9621]\n",
      " [0.9625]\n",
      " [0.9733]\n",
      " [0.9758]\n",
      " [0.9784]\n",
      " [0.97  ]\n",
      " [0.979 ]\n",
      " [0.9719]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.973280.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1200_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9688660382747787]\n",
      "\n",
      " Average accuracy across all the different runs : 0.968866.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.965 ]\n",
      " [0.9472]\n",
      " [0.9561]\n",
      " [0.9672]\n",
      " [0.9712]\n",
      " [0.9768]\n",
      " [0.9673]\n",
      " [0.974 ]\n",
      " [0.9711]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.968200.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9705798343330477]\n",
      "\n",
      " Average accuracy across all the different runs : 0.970580.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9683]\n",
      " [0.9518]\n",
      " [0.9571]\n",
      " [0.9697]\n",
      " [0.9751]\n",
      " [0.9784]\n",
      " [0.9664]\n",
      " [0.9757]\n",
      " [0.9711]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.969970.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9729601066361991]\n",
      "\n",
      " Average accuracy across all the different runs : 0.972960.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9716]\n",
      " [0.9633]\n",
      " [0.9625]\n",
      " [0.9721]\n",
      " [0.9751]\n",
      " [0.9784]\n",
      " [0.9682]\n",
      " [0.979 ]\n",
      " [0.9703]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.972660.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9676282966771399]\n",
      "\n",
      " Average accuracy across all the different runs : 0.967628.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9639]\n",
      " [0.9449]\n",
      " [0.955 ]\n",
      " [0.9684]\n",
      " [0.9696]\n",
      " [0.9751]\n",
      " [0.9655]\n",
      " [0.9707]\n",
      " [0.9711]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.967030.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9689612491669047]\n",
      "\n",
      " Average accuracy across all the different runs : 0.968961.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.965 ]\n",
      " [0.9495]\n",
      " [0.955 ]\n",
      " [0.9697]\n",
      " [0.9727]\n",
      " [0.9768]\n",
      " [0.9636]\n",
      " [0.9749]\n",
      " [0.9703]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.968360.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_1000_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_1200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9708654670094259]\n",
      "\n",
      " Average accuracy across all the different runs : 0.970865.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9861]\n",
      " [0.9683]\n",
      " [0.9529]\n",
      " [0.9571]\n",
      " [0.9709]\n",
      " [0.9751]\n",
      " [0.9784]\n",
      " [0.9655]\n",
      " [0.9782]\n",
      " [0.9703]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.970280.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_1200_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9626773302865848]\n",
      "\n",
      " Average accuracy across all the different runs : 0.962677.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9807]\n",
      " [0.9573]\n",
      " [0.9357]\n",
      " [0.9518]\n",
      " [0.9624]\n",
      " [0.9649]\n",
      " [0.9735]\n",
      " [0.9627]\n",
      " [0.9665]\n",
      " [0.9638]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.961930.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.964581548129106]\n",
      "\n",
      " Average accuracy across all the different runs : 0.964582.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9807]\n",
      " [0.9617]\n",
      " [0.9414]\n",
      " [0.9518]\n",
      " [0.9612]\n",
      " [0.9688]\n",
      " [0.9735]\n",
      " [0.9636]\n",
      " [0.9681]\n",
      " [0.967 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.963780.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_1000_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_1200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9664857659716272]\n",
      "\n",
      " Average accuracy across all the different runs : 0.966486.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9829]\n",
      " [0.9628]\n",
      " [0.946 ]\n",
      " [0.9539]\n",
      " [0.9624]\n",
      " [0.9712]\n",
      " [0.9743]\n",
      " [0.9636]\n",
      " [0.9723]\n",
      " [0.9678]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.965720.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_1200_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9481100637912977]\n",
      "\n",
      " Average accuracy across all the different runs : 0.948110.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9807]\n",
      " [0.9519]\n",
      " [0.9036]\n",
      " [0.9293]\n",
      " [0.949 ]\n",
      " [0.9509]\n",
      " [0.961 ]\n",
      " [0.9464]\n",
      " [0.9489]\n",
      " [0.951 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.947270.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9524897648290964]\n",
      "\n",
      " Average accuracy across all the different runs : 0.952490.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9797]\n",
      " [0.9508]\n",
      " [0.9127]\n",
      " [0.9357]\n",
      " [0.9539]\n",
      " [0.9564]\n",
      " [0.966 ]\n",
      " [0.9536]\n",
      " [0.9522]\n",
      " [0.955 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.951600.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1000_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9554413024850043]\n",
      "\n",
      " Average accuracy across all the different runs : 0.955441.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9797]\n",
      " [0.9508]\n",
      " [0.9219]\n",
      " [0.9378]\n",
      " [0.9563]\n",
      " [0.9595]\n",
      " [0.9685]\n",
      " [0.9555]\n",
      " [0.9589]\n",
      " [0.9566]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.954550.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_1200_dataSplit_3'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8724929589485363]\n",
      "\n",
      " Average accuracy across all the different runs : 0.872493.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9083]\n",
      " [0.8634]\n",
      " [0.8338]\n",
      " [0.8631]\n",
      " [0.8737]\n",
      " [0.9035]\n",
      " [0.8714]\n",
      " [0.8819]\n",
      " [0.8404]\n",
      " [0.8923]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.873180.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8736024579670564]\n",
      "\n",
      " Average accuracy across all the different runs : 0.873602.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9108]\n",
      " [0.8593]\n",
      " [0.8364]\n",
      " [0.8653]\n",
      " [0.8749]\n",
      " [0.8997]\n",
      " [0.8723]\n",
      " [0.8819]\n",
      " [0.8436]\n",
      " [0.8946]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.873880.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8756507638474013]\n",
      "\n",
      " Average accuracy across all the different runs : 0.875651.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9134]\n",
      " [0.8579]\n",
      " [0.8364]\n",
      " [0.869 ]\n",
      " [0.8798]\n",
      " [0.8969]\n",
      " [0.8751]\n",
      " [0.8878]\n",
      " [0.8449]\n",
      " [0.8969]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.875810.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1000_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8764188785525305]\n",
      "\n",
      " Average accuracy across all the different runs : 0.876419.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9127]\n",
      " [0.8538]\n",
      " [0.8364]\n",
      " [0.872 ]\n",
      " [0.8779]\n",
      " [0.8988]\n",
      " [0.8788]\n",
      " [0.8892]\n",
      " [0.8474]\n",
      " [0.8981]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.876510.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0075_avg_roundNum_0_globalIters_1200_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8710420756166254]\n",
      "\n",
      " Average accuracy across all the different runs : 0.871042.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9102]\n",
      " [0.8455]\n",
      " [0.8285]\n",
      " [0.8668]\n",
      " [0.8713]\n",
      " [0.9007]\n",
      " [0.8677]\n",
      " [0.8819]\n",
      " [0.8423]\n",
      " [0.8946]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.870950.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.005_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8651531962106341]\n",
      "\n",
      " Average accuracy across all the different runs : 0.865153.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9006]\n",
      " [0.8428]\n",
      " [0.8277]\n",
      " [0.8528]\n",
      " [0.8683]\n",
      " [0.8969]\n",
      " [0.8639]\n",
      " [0.8717]\n",
      " [0.8417]\n",
      " [0.882 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.864840.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.837586412904327]\n",
      "\n",
      " Average accuracy across all the different runs : 0.837586.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.872 ]\n",
      " [0.8014]\n",
      " [0.8085]\n",
      " [0.8366]\n",
      " [0.8375]\n",
      " [0.8688]\n",
      " [0.8285]\n",
      " [0.8382]\n",
      " [0.809 ]\n",
      " [0.8694]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.836990.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_2'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_0_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_1_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_2_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_3_globalIters_50_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_4_globalIters_50_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9866666666666667, 0.99, 0.9891666666666666, 0.9858333333333333, 0.9875]\n",
      "\n",
      " Average accuracy across all the different runs : 0.987833.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9867]\n",
      " [0.9967]\n",
      " [0.9833]\n",
      " [0.9783]\n",
      " [0.9867]\n",
      " [0.99  ]\n",
      " [0.9883]\n",
      " [0.9933]\n",
      " [0.985 ]\n",
      " [0.99  ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.987830.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_0_globalIters_50_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_1_globalIters_50_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_2_globalIters_50_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_3_globalIters_50_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_4_globalIters_50_dataSplit_1'\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9891666666666666, 0.9933333333333333, 0.9933333333333333, 0.9875, 0.99]\n",
      "\n",
      " Average accuracy across all the different runs : 0.990667.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9883]\n",
      " [0.9967]\n",
      " [0.9917]\n",
      " [0.985 ]\n",
      " [0.9883]\n",
      " [0.9933]\n",
      " [0.99  ]\n",
      " [0.9967]\n",
      " [0.985 ]\n",
      " [0.9917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.990670.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Datasplit-1_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9916666666666667, 0.9941666666666666, 0.9941666666666666, 0.9883333333333333, 0.9925]\n",
      "\n",
      " Average accuracy across all the different runs : 0.992167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9883]\n",
      " [0.9983]\n",
      " [0.995 ]\n",
      " [0.985 ]\n",
      " [0.9917]\n",
      " [0.9933]\n",
      " [0.9917]\n",
      " [0.9983]\n",
      " [0.9867]\n",
      " [0.9933]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.992160.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/Datasplit-2_MNIST/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_0_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_1_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_2_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_3_globalIters_25_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_4_globalIters_25_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.09610788665073404, 0.09831868225655031, 0.10411332991978153, 0.1001962959801997, 0.09668885475337088]\n",
      "\n",
      " Average accuracy across all the different runs : 0.099085.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.1914]\n",
      " [0.1448]\n",
      " [0.1859]\n",
      " [0.1582]\n",
      " [0.1519]\n",
      " [0.2262]\n",
      " [0.1689]\n",
      " [0.1805]\n",
      " [0.1783]\n",
      " [0.1628]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.174890.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_0_globalIters_25_dataSplit_2',\n",
    "    'Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_1_globalIters_25_dataSplit_2',\n",
    "    'Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_2_globalIters_25_dataSplit_2',\n",
    "    'Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_3_globalIters_25_dataSplit_2',\n",
    "    'Mnist_pFedMe_0.01_1.0_15_10u_128b_20_5_0.001_0_roundNum_4_globalIters_25_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4)) \n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_50_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_50_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.1692557186753158, 0.19962447725527013, 0.17033623485236388, 0.18315268413416402, 0.2196620583717358]\n",
      "\n",
      " Average accuracy across all the different runs : 0.188406.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.2009]\n",
      " [0.1802]\n",
      " [0.1841]\n",
      " [0.1622]\n",
      " [0.1729]\n",
      " [0.2441]\n",
      " [0.1671]\n",
      " [0.1902]\n",
      " [0.1869]\n",
      " [0.1704]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.185900.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_50_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_50_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_50_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_50_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_50_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))2\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.17949812222601572, 0.2320559870273961, 0.18501450759515276, 0.20286762823248272, 0.24970131421744324]\n",
      "\n",
      " Average accuracy across all the different runs : 0.209828.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.2224]\n",
      " [0.2302]\n",
      " [0.2055]\n",
      " [0.1894]\n",
      " [0.2065]\n",
      " [0.2492]\n",
      " [0.1761]\n",
      " [0.1994]\n",
      " [0.1975]\n",
      " [0.1971]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.207330.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_2\n",
      "/home/adgdri/pFedMe/results/Datasplit-2_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_2\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.21252987367702286, 0.27302210463429205, 0.24364225977129203, 0.2502347017154562, 0.28375149342891276]\n",
      "\n",
      " Average accuracy across all the different runs : 0.252636.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.2995]\n",
      " [0.2635]\n",
      " [0.2609]\n",
      " [0.2632]\n",
      " [0.2291]\n",
      " [0.2825]\n",
      " [0.2258]\n",
      " [0.2268]\n",
      " [0.2313]\n",
      " [0.2235]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.250610.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_2',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_2',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % (np.round(perUserAcc.T, 4)))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/Datasplit-3_MNIST/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_25_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.34809523809523807, 0.37396438434434814, 0.3500618988667746, 0.34809523809523807, 0.3406666666666667]\n",
      "\n",
      " Average accuracy across all the different runs : 0.352177.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3729]\n",
      " [0.3515]\n",
      " [0.3832]\n",
      " [0.5184]\n",
      " [0.1163]\n",
      " [0.2258]\n",
      " [0.477 ]\n",
      " [0.3474]\n",
      " [0.3353]\n",
      " [0.3151]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.344290.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_25_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_50_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.3939047619047619, 0.406913627273593, 0.3959622893057804, 0.3939047619047619, 0.39904761904761904]\n",
      "\n",
      " Average accuracy across all the different runs : 0.397947.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.4034]\n",
      " [0.348 ]\n",
      " [0.3859]\n",
      " [0.5184]\n",
      " [0.3836]\n",
      " [0.3896]\n",
      " [0.4768]\n",
      " [0.3771]\n",
      " [0.397 ]\n",
      " [0.3425]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.402230.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_50_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.3965714285714286, 0.4105323302542615, 0.396819350538044, 0.3965714285714286, 0.3924761904761905]\n",
      "\n",
      " Average accuracy across all the different runs : 0.398594.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3988]\n",
      " [0.3755]\n",
      " [0.3877]\n",
      " [0.5179]\n",
      " [0.3751]\n",
      " [0.3829]\n",
      " [0.4762]\n",
      " [0.3728]\n",
      " [0.3901]\n",
      " [0.3478]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.402480.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_100_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Datasplit-3_MNIST/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.3959047619047619, 0.40948481097038375, 0.40024759546709837, 0.3944761904761905, 0.39504761904761904]\n",
      "\n",
      " Average accuracy across all the different runs : 0.399032.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3993]\n",
      " [0.3748]\n",
      " [0.3899]\n",
      " [0.5184]\n",
      " [0.3763]\n",
      " [0.3861]\n",
      " [0.4769]\n",
      " [0.3648]\n",
      " [0.3897]\n",
      " [0.3558]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.403200.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_200_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:, -1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the global directory path.\n",
    "directoryPath = '/home/adgdri/pFedMe/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_25_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_25_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.2944761904761905, 0.3006380344729073, 0.29054375773735835, 0.29438095238095235, 0.2935238095238095]\n",
      "\n",
      " Average accuracy across all the different runs : 0.294713.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.1742]\n",
      " [0.3378]\n",
      " [0.3817]\n",
      " [0.5166]\n",
      " [0.0008]\n",
      " [0.0133]\n",
      " [0.4398]\n",
      " [0.3396]\n",
      " [0.314 ]\n",
      " [0.2657]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.278350.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_25_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_25_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_50_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_50_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.3383809523809524, 0.36082277878297303, 0.33006380344729075, 0.3383809523809524, 0.33276190476190476]\n",
      "\n",
      " Average accuracy across all the different runs : 0.340082.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3693]\n",
      " [0.3498]\n",
      " [0.3832]\n",
      " [0.5184]\n",
      " [0.0239]\n",
      " [0.145 ]\n",
      " [0.4772]\n",
      " [0.3494]\n",
      " [0.3416]\n",
      " [0.308 ]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.326580.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_50_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_50_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_100_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_100_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.39095238095238094, 0.39805732787353587, 0.4005332825445196, 0.39095238095238094, 0.3840952380952381]\n",
      "\n",
      " Average accuracy across all the different runs : 0.392918.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3987]\n",
      " [0.359 ]\n",
      " [0.3852]\n",
      " [0.5184]\n",
      " [0.3599]\n",
      " [0.3917]\n",
      " [0.4766]\n",
      " [0.365 ]\n",
      " [0.3778]\n",
      " [0.3382]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.397050.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_100_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_100_dataSplit_3',\n",
    "]\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num Epochs: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.39066666666666666, 0.40415198552518805, 0.39415293781544614, 0.39066666666666666, 0.37266666666666665]\n",
      "\n",
      " Average accuracy across all the different runs : 0.390461.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.3967]\n",
      " [0.3571]\n",
      " [0.3868]\n",
      " [0.5177]\n",
      " [0.3676]\n",
      " [0.3751]\n",
      " [0.4728]\n",
      " [0.3724]\n",
      " [0.3626]\n",
      " [0.3368]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.394560.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_0_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_1_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_2_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_3_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_5_10u_128b_20_5_0.001_0_roundNum_4_globalIters_200_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9125, 0.9075, 0.9433333333333334, 0.9166666666666666, 0.9175]\n",
      "\n",
      " Average accuracy across all the different runs : 0.919500.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.925 ]\n",
      " [0.9183]\n",
      " [0.9   ]\n",
      " [0.9183]\n",
      " [0.925 ]\n",
      " [0.905 ]\n",
      " [0.9233]\n",
      " [0.93  ]\n",
      " [0.9317]\n",
      " [0.9183]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.919490.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.8841666666666667, 0.8733333333333333, 0.9225, 0.885, 0.8758333333333334]\n",
      "\n",
      " Average accuracy across all the different runs : 0.888167.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.8917]\n",
      " [0.8983]\n",
      " [0.85  ]\n",
      " [0.8967]\n",
      " [0.8883]\n",
      " [0.8533]\n",
      " [0.895 ]\n",
      " [0.9067]\n",
      " [0.91  ]\n",
      " [0.8917]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.888170.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_1_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_2_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_3_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.001_1.0_15_10u_128b_20_5_0.001_avg_roundNum_4_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_1_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_2_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_3_globalIters_800_dataSplit_1\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_4_globalIters_800_dataSplit_1\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9533333333333334, 0.9425, 0.97, 0.9316666666666666, 0.94]\n",
      "\n",
      " Average accuracy across all the different runs : 0.947500.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9483]\n",
      " [0.9583]\n",
      " [0.9317]\n",
      " [0.9433]\n",
      " [0.9367]\n",
      " [0.9417]\n",
      " [0.95  ]\n",
      " [0.9583]\n",
      " [0.945 ]\n",
      " [0.9617]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.947500.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_0_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_1_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_2_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_3_globalIters_800_dataSplit_1',\n",
    "    'Mnist_pFedMe_p_0.02_1.0_15_10u_128b_20_5_0.0025_avg_roundNum_4_globalIters_800_dataSplit_1',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasplit-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_1000_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_1000_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_1000_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_1000_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9716271541464343, 0.9722936303913168, 0.9741001713959246, 0.970386593029899, 0.9753380308512665]\n",
      "\n",
      " Average accuracy across all the different runs : 0.972749.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9859]\n",
      " [0.972 ]\n",
      " [0.9619]\n",
      " [0.9615]\n",
      " [0.9749]\n",
      " [0.9758]\n",
      " [0.982 ]\n",
      " [0.9687]\n",
      " [0.9673]\n",
      " [0.9747]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.972470.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_1000_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_1000_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_1000_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_1000_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_1000_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_200_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_200_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9558221460535086, 0.954965248024374, 0.9584840982669968, 0.9513426014092554, 0.9604837173871643]\n",
      "\n",
      " Average accuracy across all the different runs : 0.956220.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9821]\n",
      " [0.9553]\n",
      " [0.926 ]\n",
      " [0.9427]\n",
      " [0.9605]\n",
      " [0.9595]\n",
      " [0.9697]\n",
      " [0.9535]\n",
      " [0.9424]\n",
      " [0.9647]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.955640.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_200_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_200_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_400_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_400_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_400_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_400_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_400_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.9641054936684756, 0.9632485956393412, 0.9677204342030089, 0.9599123976385451, 0.9681013140354219]\n",
      "\n",
      " Average accuracy across all the different runs : 0.964618.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9833]\n",
      " [0.9641]\n",
      " [0.945 ]\n",
      " [0.9534]\n",
      " [0.9656]\n",
      " [0.9678]\n",
      " [0.9763]\n",
      " [0.9603]\n",
      " [0.9563]\n",
      " [0.9697]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.964180.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_0_globalIters_400_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_1_globalIters_400_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_2_globalIters_400_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_3_globalIters_400_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_1.0_15_10u_128b_20_5_0.01_avg_roundNum_4_globalIters_400_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST pFedMe paper check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_0_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_1_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_2_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_3_globalIters_800_dataSplit_3\n",
      "/home/adgdri/pFedMe/results/Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_4_globalIters_800_dataSplit_3\n",
      "----------------------------------------\n",
      "\n",
      " Average accuracies across all the users over different runs : [0.982290774064553, 0.9811482433590403, 0.9833365073319368, 0.9798133688821177, 0.984288706912969]\n",
      "\n",
      " Average accuracy across all the different runs : 0.982176.\n",
      "\n",
      " Average per user accuracy averaged over different runs: \n",
      " [[0.9897]\n",
      " [0.9834]\n",
      " [0.9753]\n",
      " [0.9764]\n",
      " [0.981 ]\n",
      " [0.9848]\n",
      " [0.9884]\n",
      " [0.9801]\n",
      " [0.9776]\n",
      " [0.9829]].\n",
      "\n",
      " Per-user averaged accuracy: \n",
      " 0.981960.\n"
     ]
    }
   ],
   "source": [
    "fileNames = [\n",
    "    'Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_0_globalIters_800_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_1_globalIters_800_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_2_globalIters_800_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_3_globalIters_800_dataSplit_3',\n",
    "    'Mnist_pFedMe_p_0.01_2.0_30_10u_20b_20_5_0.05_avg_roundNum_4_globalIters_800_dataSplit_3',\n",
    "]\n",
    "\n",
    "\n",
    "# Get the number of users.\n",
    "numUsers = int(fileNames[0].split('u')[0].split('_')[-1])\n",
    "\n",
    "avgPersAcc = []\n",
    "perUserAcc = np.zeros((1, numUsers))\n",
    "\n",
    "for fileName in fileNames:\n",
    "    ob = simple_read_data(directoryPath + fileName)\n",
    "    avgPersAcc.append( ob['rs_glob_acc'][-1] )\n",
    "    # Take the per user accuracy from the last epoch.\n",
    "    perUserAcc += ob['perUserAccs'][:,-1, :]\n",
    "\n",
    "# Average out over the different runs.\n",
    "perUserAcc /= len(fileNames)\n",
    "\n",
    "\n",
    "print ('----------------------------------------')\n",
    "\n",
    "print ('\\n Average accuracies across all the users over different runs : %s' % avgPersAcc)\n",
    "\n",
    "print ('\\n Average accuracy across all the different runs : %f.' % np.mean(avgPersAcc) )\n",
    "\n",
    "print ('\\n Average per user accuracy averaged over different runs: \\n %s.' % np.round(perUserAcc.T, 4))\n",
    "\n",
    "print ('\\n Per-user averaged accuracy: \\n %f.' % np.mean(np.round(perUserAcc.T, 4))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
